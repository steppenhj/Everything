# -*- coding: utf-8 -*-
"""ë°•í•´ì§„.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gvv7F5WUlnaY6qvhKhWWABRf6SGUCiAI
"""

import os
import shutil
import zipfile

# ê²½ë¡œ ì„¤ì • (ìŠ¤í¬ë¦°ìƒ· ê¸°ë°˜)
base_dir = '/content/drive/MyDrive/DLProject'
zip_file_path = os.path.join(base_dir, 'cub2002011.zip') # zip íŒŒì¼
extract_to_path = os.path.join(base_dir, 'cub200')        # ì••ì¶• í’€ ìœ„ì¹˜
corrupted_dir = os.path.join(extract_to_path, 'CUB_200_2011') # ë§ê°€ì§„ í´ë”

print(f"ì‘ì—… ìœ„ì¹˜: {extract_to_path}")

# 1. ê¸°ì¡´(ìœ ì‹¤ëœ) í´ë” ì‚­ì œ
if os.path.exists(corrupted_dir):
    print(f"ê¸°ì¡´ì˜ ë¶ˆì™„ì „í•œ í´ë”ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤... (ì‹œê°„ì´ ì¢€ ê±¸ë¦´ ìˆ˜ ìˆì–´ìš”)")
    try:
        shutil.rmtree(corrupted_dir)
        print("âœ… ê¸°ì¡´ í´ë” ì‚­ì œ ì™„ë£Œ!")
    except Exception as e:
        print(f"ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ë¬´ì‹œí•˜ê³  ì§„í–‰í•©ë‹ˆë‹¤): {e}")
else:
    print("ê¸°ì¡´ í´ë”ê°€ ì—†ë„¤ìš”. ë°”ë¡œ ì••ì¶• í•´ì œë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.")

# 2. ì••ì¶• í•´ì œ (êµ¬ê¸€ ì„œë²„ì—ì„œ ìˆ˜í–‰í•˜ë¯€ë¡œ ë¹ ë¥´ê³  ì •í™•í•¨)
if os.path.exists(zip_file_path):
    print(f"ğŸš€ ì••ì¶• í•´ì œ ì‹œì‘! ({zip_file_path})")
    print("1~2ë¶„ ì •ë„ ê±¸ë¦½ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")

    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
        zip_ref.extractall(extract_to_path)

    print("âœ… ì••ì¶• í•´ì œ ì„±ê³µ! ëª¨ë“  íŒŒì¼ì´ ë³µêµ¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
else:
    print(f"âŒ Zip íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {zip_file_path}")
    print("íŒŒì¼ëª…ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")

from google.colab import drive
drive.mount('/content/drive')

import os
import pandas as pd
from PIL import Image
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import numpy as np

base_path = '/content/drive/MyDrive/DLProject/cub200/CUB_200_2011'

# ë°ì´í„° ì •ë³´ ì½ê³ , í•™ìŠµí…ŒìŠ¤íŠ¸ë¡œ ë‚˜ëˆ„ê¸°
def load_data_frame(root_dir):
  images_txt = pd.read_csv(os.path.join(root_dir, 'images.txt'), sep=' ', names=['img_id', 'filepath'])

  labels_txt = pd.read_csv(os.path.join(root_dir, 'image_class_labels.txt'), sep=' ', names=['img_id', 'label'])

  data = images_txt.merge(labels_txt, on='img_id')
  return data

full_data = load_data_frame(base_path)

# í›ˆë ¨80%, í…ŒìŠ¤íŠ¸20%ë¡œ ì„¤ì •
train_df, test_df = train_test_split(
    full_data,
    test_size=0.2,
    stratify=full_data['label'], #ëª¨ë“  ìƒˆ ì¢…ë¥˜ê°€ ê³¨ê³ ë£¨ ì„ì´ë„ë¡
    random_state=42
)

print(f"ì „ì²´ ë°ì´í„°: {len(full_data)}ê°œ")
print(f"í•™ìŠµìš© ë°ì´í„°: {len(train_df)}ê°œ")
print(f"í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°: {len(test_df)}ê°œ")

class CUB200Dataset(Dataset):
  def __init__(self, dataframe, root_dir, transform=None):
    self.root_dir = root_dir
    self.transform = transform
    self.data = dataframe.reset_index(drop=True)

    self.image_paths = self.data['filepath'].values
    self.labels = self.data['label'].values - 1

  def __len__(self):
    return len(self.image_paths)

  def __getitem__(self, idx):
    img_path = os.path.join(self.root_dir, 'images', self.image_paths[idx])

    try:
      image = Image.open(img_path).convert('RGB')
    except FileNotFoundError:
      print(f"ê²½ë¡œ ì—ëŸ¬: {img_path}")
      image = Image.new('RGB', (224, 224))

    label = self.labels[idx]

    if self.transform:
      image = self.transform(image)

    return image, label

  # ë°ì´í„° ë¡œë” ìƒì„±, í…ŒìŠ¤íŠ¸
data_transforms = {
    'train': transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(), #ì¦ê°•: ì¢Œìš°ë°˜ì „
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
     ]),
    'test': transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224,  0.225])
     ]),
 }

#ì •ê·œí™”ì— ì—ëŸ¬ ë©”ì‹œì§€ ë•Œë¬¸ì— ì›ë˜ë¡œ ë³µêµ¬í•˜ëŠ” ê±° ì¶”ê°€
def imshow_unorm(tensor,title=None):
  img = tensor.cpu().clone()
  img = img.permute(1,2,0).numpy()

  mean = np.array([0.485, 0.456, 0.406])
  std = np.array([0.229, 0.224, 0.225])

  img = img*std + mean

  img = np.clip(img, 0, 1)

  plt.imshow(img)
  if title:
    plt.title(title)
  plt.axis('off')
  plt.show()

train_dataset = CUB200Dataset(train_df, base_path, transform=data_transforms['train'])
test_dataset = CUB200Dataset(test_df, base_path, transform=data_transforms['test'])

train_loader=DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader=DataLoader(test_dataset, batch_size=32, shuffle=False)

print("\në°ì´í„° ë¡œë”©. ì²«ë²ˆì§¸ ë°°ì¹˜í™•ì¸")
images, labels = next(iter(train_loader))

imshow_unorm(images[0], title=f"Label ID: {labels[0].item()}")

import torch.nn as nn
import torch.optim as optim
from torchvision import models
import time
import copy

#GPU ì„¤ì •
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(f"í˜„ì¬ í•™ìŠµ ì¥ì¹˜: {device}")

# ResNet50 ëª¨ë¸ ë¡œë“œ ë° ìˆ˜ì •
model = models.resnet50(pretrained=True)
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 200)
model = model.to(device)

# ì†ì‹¤í•¨ìˆ˜, ìµœì í™”
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)

# í•™ìŠµ í•¨ìˆ˜ ì •ì˜
def train_model(model, criterion, optimizer, scheduler, num_epochs=10):
  since = time.time()
  best_model_wts = copy.deepcopy(model.state_dict())
  best_acc=0.0

  history = {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []}

  for epoch in range(num_epochs):
    print(f'\nEpoch {epoch+1}/{num_epochs}')
    print('-' * 10)

    for phase in ['train', 'test']:
      if phase == 'train':
        model.train()
        dataloader = train_loader
      else:
        model.eval()
        dataloader = test_loader

      running_loss = 0.0
      running_corrects = 0

      for inputs, labels in dataloader:
        inputs = inputs.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()

        with torch.set_grad_enabled(phase == 'train'):
          outputs = model(inputs)
          _, preds = torch.max(outputs, 1)
          loss = criterion(outputs, labels)

          if phase == 'train':
            loss.backward()
            optimizer.step()

        running_loss += loss.item() * inputs.size(0)
        running_corrects += torch.sum(preds==labels.data)

      if phase == 'train':
        scheduler.step()

      epoch_loss = running_loss / len(dataloader.dataset)
      epoch_acc = running_corrects.double() / len(dataloader.dataset)

      print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')

      history[f'{phase}_loss'].append(epoch_loss)
      history[f'{phase}_acc'].append(epoch_acc.item())

      #ìµœê³  ì„±ëŠ¥
      if phase == 'test' and epoch_acc > best_acc:
        best_acc = epoch_acc
        best_model_wts = copy.deepcopy(model.state_dict())
        torch.save(model.state_dict(), 'best_resnet50.pth')

  time_elapsed = time.time() - since
  print(f'\ní•™ìŠµì™„ë£Œ ì†Œìš”ì‹œê°„: {time_elapsed // 60: .0f}ë¶„ {time_elapsed % 60:.0f}ì´ˆ')
  print(f'Best Test Acc: {best_acc:.4f}')

  model.load_state_dict(best_model_wts)
  return model, history

#í•™ìŠµ ì‹¤í–‰
trained_model, history = train_model(model, criterion, optimizer, scheduler, num_epochs=10)

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
import numpy as np

#í•™ìŠµ ê²°ê³¼ ê·¸ë˜í”„
def plot_training_history(history):
  acc = history['train_acc']
  val_acc = history['test_acc']
  loss = history['train_loss']
  val_loss = history['test_loss']
  epochs = range(1, len(acc) + 1)

  plt.figure(figsize=(12, 5))

  #ì •í™•ë„ ê·¸ë˜í”„
  plt.subplot(1, 2, 1)
  plt.plot(epochs, acc, 'b-', label='Training Acc')
  plt.plot(epochs, val_acc, 'r-', label='Test Acc')
  plt.title('Training and Test Accuracy')
  plt.legend()

  #ì†ì‹¤ ê·¸ë˜í”„
  plt.subplot(1, 2, 2)
  plt.plot(epochs, loss, 'b-', label='Training Loss')
  plt.plot(epochs, val_loss, 'r-', label='Test Loss')
  plt.title('Training and Test Loss')
  plt.legend()

  plt.show()

#í˜¼ë™í–‰ë ¬ ì‹œê°í™”
def plot_confusion_matrix(model, dataloader):
  model.eval()
  all_preds = []
  all_labels = []

  print("í˜¼ë™ í–‰ë ¬ ë°ì´í„° ì¶”ì¶œ ì¤‘")

  with torch.no_grad():
    for inputs, labels in dataloader:
      inputs = inputs.to(device)
      outputs = model(inputs)
      _, preds = torch.max(outputs, 1)

      all_preds.extend(preds.cpu().numpy())
      all_labels.extend(labels.numpy())

  cm = confusion_matrix(all_labels, all_preds)

  plt.figure(figsize=(10, 8))
  sns.heatmap(cm, cmap='Blues')
  plt.title("Confusion Matrix (200 Classes)")
  plt.xlabel("Predicted")
  plt.ylabel("True")
  plt.show()

#ê·¸ë˜í”„ ê·¸ë¦¬ê³  í˜¼ë™í–‰ë ¬ ê·¸ë¦¬ê¸°
plot_training_history(history)
plot_confusion_matrix(trained_model, test_loader)

!pip install grad-cam

from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget
from pytorch_grad_cam.utils.image import show_cam_on_image
import numpy as np
import cv2
import matplotlib.pyplot as plt

#ë ˆì´ì–´ ì„¤ì •
target_layers = [model.layer4[-1]]

# Grad-CAM ê°ì²´ ìƒì„±
cam = GradCAM(model=model, target_layers=target_layers)

# ì‹œê°í™” í•¨ìˆ˜ ì •ì˜
def visualize_gradcam(model, dataloader, num_images=10):
  model.eval()

  images, labels = next(iter(dataloader))
  images = images.to(device)

  fig, axes = plt.subplots(2, 5, figsize=(20, 8))
  axes = axes.flatten()

  print(f"Test ë°ì´í„°ì…‹ì—ì„œ {num_images}ì¥ì„ ë½‘ì•„ ë¶„ì„ ì¤‘")

  for i in range(num_images):
    input_tensor = images[i].unsqueeze(0)

    grayscale_cam = cam(input_tensor=input_tensor, targets=None)

    grayscale_cam = grayscale_cam[0, :]

    img = images[i].cpu().permute(1, 2, 0).numpy()
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    rgb_img = img*std + mean
    rgb_img = np.clip(rgb_img, 0, 1)

    # ì›ë³¸ ìœ„ì— íˆíŠ¸ë§µ ê²¹ì¹˜ê¸°
    visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)

    axes[i].imshow(visualization)
    axes[i].set_title(f"True: {labels[i].item()}")
    axes[i].axis('off')

  plt.tight_layout()
  plt.show()

visualize_gradcam(model, test_loader, num_images=10)

from torchvision.models.detection import fasterrcnn_resnet50_fpn
from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.image import show_cam_on_image
import cv2
import numpy as np
import matplotlib.pyplot as plt
import torch

# 1. Detection ëª¨ë¸ ë¡œë“œ
print("Detection ëª¨ë¸(Faster R-CNN) ë¡œë“œ ì¤‘...")
detection_model = fasterrcnn_resnet50_fpn(pretrained=True)
detection_model = detection_model.to(device)
detection_model.eval()

COCO_BIRD_LABEL = 16

# 2. IoU ê³„ì‚° ë° ì‹œê°í™” í•¨ìˆ˜ (ìµœì¢… ìˆ˜ì •: Tensor/Numpy ì¶©ëŒ í•´ê²°)
def calculate_iou_and_visualize(classification_model, detection_model, dataloader, num_samples=5):
    classification_model.eval()

    # Grad-CAM ì„¤ì •
    target_layers = [classification_model.layer4[-1]]
    cam = GradCAM(model=classification_model, target_layers=target_layers)

    images, labels = next(iter(dataloader))
    images = images.to(device)

    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5 * num_samples))
    print(f"\nì´ {num_samples}ê°œ ìƒ˜í”Œì— ëŒ€í•´ IoU ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n")

    # [ìˆ˜ì • 1] GPU ì—°ì‚°ìš© Tensor (Detection ì…ë ¥ìš©)
    mean_tensor = torch.tensor([0.485, 0.456, 0.406]).to(device).view(1, 3, 1, 1)
    std_tensor = torch.tensor([0.229, 0.224, 0.225]).to(device).view(1, 3, 1, 1)

    # [ìˆ˜ì • 2] ì‹œê°í™”ìš© Numpy Array (ë§ˆì§€ë§‰ ì¶œë ¥ìš©)
    mean_numpy = np.array([0.485, 0.456, 0.406])
    std_numpy = np.array([0.229, 0.224, 0.225])

    for i in range(num_samples):
        img_tensor = images[i].unsqueeze(0)

        # --- [A] Detection ê²°ê³¼ (Bounding Box) ---
        # ì •ê·œí™” í•´ì œ (GPU Tensor ì—°ì‚°)
        detection_input = img_tensor * std_tensor + mean_tensor
        detection_input = torch.clamp(detection_input, 0, 1)

        with torch.no_grad():
            prediction = detection_model(detection_input)

        pred_boxes = prediction[0]['boxes']
        pred_labels = prediction[0]['labels']
        pred_scores = prediction[0]['scores']

        # 'ìƒˆ'ì´ë©´ì„œ 'í™•ì‹  > 0.5'ì¸ ë°•ìŠ¤ ì°¾ê¸°
        bird_indices = (pred_labels == COCO_BIRD_LABEL) & (pred_scores > 0.5)
        bird_boxes = pred_boxes[bird_indices]

        if len(bird_boxes) > 0:
            x1, y1, x2, y2 = bird_boxes[0].cpu().numpy().astype(int)
            target_box = [x1, y1, x2, y2]
            box_found = True
        else:
            target_box = [0, 0, 224, 224]
            box_found = False

        # Box Mask ìƒì„±
        box_mask = np.zeros((224, 224), dtype=np.uint8)
        cv2.rectangle(box_mask, (target_box[0], target_box[1]), (target_box[2], target_box[3]), 1, -1)

        # --- [B] Grad-CAM Heatmap ---
        grayscale_cam = cam(input_tensor=img_tensor, targets=None)[0, :]
        heatmap_mask = np.where(grayscale_cam > 0.2, 1, 0).astype(np.uint8)

        # --- [C] IoU ê³„ì‚° ---
        intersection = (box_mask & heatmap_mask).sum()
        union = (box_mask | heatmap_mask).sum()
        iou = intersection / union if union > 0 else 0

        # --- [D] ì‹œê°í™” ---
        # ì›ë³¸ ë³µêµ¬ (CPU Numpy ì—°ì‚°)
        img_np = images[i].cpu().permute(1, 2, 0).numpy()

        # [ìˆ˜ì • 3] ì—¬ê¸°ì„œ mean_numpy, std_numpy ì‚¬ìš©! (ì—ëŸ¬ í•´ê²° í¬ì¸íŠ¸)
        rgb_img = np.clip(img_np * std_numpy + mean_numpy, 0, 1)

        # 1. Detection Box
        img_with_box = rgb_img.copy()
        color = (0, 1, 0) if box_found else (1, 0, 0)
        cv2.rectangle(img_with_box, (target_box[0], target_box[1]), (target_box[2], target_box[3]), color, 2)

        # 2. Heatmap
        visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)

        # 3. Overlap
        overlap_vis = np.zeros((224, 224, 3))
        overlap_vis[:, :, 1] = box_mask      # Green
        overlap_vis[:, :, 0] = heatmap_mask  # Red

        # ì¶œë ¥
        axes[i, 0].imshow(img_with_box)
        title = "Detection Box (Found)" if box_found else "Detection Failed"
        axes[i, 0].set_title(title)
        axes[i, 0].axis('off')

        axes[i, 1].imshow(visualization)
        axes[i, 1].set_title(f"Grad-CAM Heatmap")
        axes[i, 1].axis('off')

        axes[i, 2].imshow(overlap_vis)
        axes[i, 2].set_title(f"Overlap (IoU: {iou:.4f})")
        axes[i, 2].axis('off')

    plt.tight_layout()
    plt.show()

# ì‹¤í–‰
calculate_iou_and_visualize(trained_model, detection_model, test_loader, num_samples=10)