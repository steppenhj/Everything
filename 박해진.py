# -*- coding: utf-8 -*-
"""박해진.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gvv7F5WUlnaY6qvhKhWWABRf6SGUCiAI
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import pandas as pd
from PIL import Image
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import numpy as np

base_path = '/content/drive/MyDrive/DLProject/cub200/CUB_200_2011'

# 데이터 정보 읽고, 학습테스트로 나누기
def load_data_frame(root_dir):
  images_txt = pd.read_csv(os.path.join(root_dir, 'images.txt'), sep=' ', names=['img_id', 'filepath'])

  labels_txt = pd.read_csv(os.path.join(root_dir, 'image_class_labels.txt'), sep=' ', names=['img_id', 'label'])

  data = images_txt.merge(labels_txt, on='img_id')
  return data

full_data = load_data_frame(base_path)

# 훈련80%, 테스트20%로 설정
train_df, test_df = train_test_split(
    full_data,
    test_size=0.2,
    stratify=full_data['label'], #모든 새 종류가 골고루 섞이도록
    random_state=42
)

print(f"전체 데이터: {len(full_data)}개")
print(f"학습용 데이터: {len(train_df)}개")
print(f"테스트용 데이터: {len(test_df)}개")

class CUB200Dataset(Dataset):
  def __init__(self, dataframe, root_dir, transform=None):
    self.root_dir = root_dir
    self.transform = transform
    self.data = dataframe.reset_index(drop=True)

    self.image_paths = self.data['filepath'].values
    self.labels = self.data['label'].values - 1

  def __len__(self):
    return len(self.image_paths)

  def __getitem__(self, idx):
    img_path = os.path.join(self.root_dir, 'images', self.image_paths[idx])

    try:
      image = Image.open(img_path).convert('RGB')
    except FileNotFoundError:
      print(f"경로 에러: {img_path}")
      image = Image.new('RGB', (224, 224))

    label = self.labels[idx]

    if self.transform:
      image = self.transform(image)

    return image, label

  # 데이터 로더 생성, 테스트
data_transforms = {
    'train': transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(), #증강: 좌우반전
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
     ]),
    'test': transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224,  0.225])
     ]),
 }

#정규화에 에러 메시지 때문에 원래로 복구하는 거 추가
def imshow_unorm(tensor,title=None):
  img = tensor.cpu().clone()
  img = img.permute(1,2,0).numpy()

  mean = np.array([0.485, 0.456, 0.406])
  std = np.array([0.229, 0.224, 0.225])

  img = img*std + mean

  img = np.clip(img, 0, 1)

  plt.imshow(img)
  if title:
    plt.title(title)
  plt.axis('off')
  plt.show()

train_dataset = CUB200Dataset(train_df, base_path, transform=data_transforms['train'])
test_dataset = CUB200Dataset(test_df, base_path, transform=data_transforms['test'])

train_loader=DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader=DataLoader(test_dataset, batch_size=32, shuffle=False)

print("\n데이터 로딩. 첫번째 배치확인")
images, labels = next(iter(train_loader))

imshow_unorm(images[0], title=f"Label ID: {labels[0].item()}")

import torch.nn as nn
import torch.optim as optim
from torchvision import models
import time
import copy

#GPU 설정
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(f"현재 학습 장치: {device}")

# ResNet50 모델 로드 및 수정
model = models.resnet50(pretrained=True)
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 200)
model = model.to(device)

# 손실함수, 최적화
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)

# 학습 함수 정의
def train_model(model, criterion, optimizer, scheduler, num_epochs=10):
  since = time.time()
  best_model_wts = copy.deepcopy(model.state_dict())
  best_acc=0.0

  history = {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []}

  for epoch in range(num_epochs):
    print(f'\nEpoch {epoch+1}/{num_epochs}')
    print('-' * 10)

    for phase in ['train', 'test']:
      if phase == 'train':
        model.train()
        dataloader = train_loader
      else:
        model.eval()
        dataloader = test_loader

      running_loss = 0.0
      running_corrects = 0

      for inputs, labels in dataloader:
        inputs = inputs.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()

        with torch.set_grad_enabled(phase == 'train'):
          outputs = model(inputs)
          _, preds = torch.max(outputs, 1)
          loss = criterion(outputs, labels)

          if phase == 'train':
            loss.backward()
            optimizer.step()

        running_loss += loss.item() * inputs.size(0)
        running_corrects += torch.sum(preds==labels.data)

      if phase == 'train':
        scheduler.step()

      epoch_loss = running_loss / len(dataloader.dataset)
      epoch_acc = running_corrects.double() / len(dataloader.dataset)

      print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')

      history[f'{phase}_loss'].append(epoch_loss)
      history[f'{phase}_acc'].append(epoch_acc.item())

      #최고 성능
      if phase == 'test' and epoch_acc > best_acc:
        best_acc = epoch_acc
        best_model_wts = copy.deepcopy(model.state_dict())
        torch.save(model.state_dict(), 'best_resnet50.pth')

  time_elapsed = time.time() - since
  print(f'\n학습완료 소요시간: {time_elapsed // 60: .0f}분 {time_elapsed % 60:.0f}초')
  print(f'Best Test Acc: {best_acc:.4f}')

  model.load_state_dict(best_model_wts)
  return model, history

#학습 실행
trained_model, history = train_model(model, criterion, optimizer, scheduler, num_epochs=10)

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
import numpy as np

#학습 결과 그래프
def plot_training_history(history):
  acc = history['train_acc']
  val_acc = history['test_acc']
  loss = history['train_loss']
  val_loss = history['test_loss']
  epochs = range(1, len(acc) + 1)

  plt.figure(figsize=(12, 5))

  #정확도 그래프
  plt.subplot(1, 2, 1)
  plt.plot(epochs, acc, 'b-', label='Training Acc')
  plt.plot(epochs, val_acc, 'r-', label='Test Acc')
  plt.title('Training and Test Accuracy')
  plt.legend()

  #손실 그래프
  plt.subplot(1, 2, 2)
  plt.plot(epochs, loss, 'b-', label='Training Loss')
  plt.plot(epochs, val_loss, 'r-', label='Test Loss')
  plt.title('Training and Test Loss')
  plt.legend()

  plt.show()

#혼동행렬 시각화
def plot_confusion_matrix(model, dataloader):
  model.eval()
  all_preds = []
  all_labels = []

  print("혼동 행렬 데이터 추출 중")

  with torch.no_grad():
    for inputs, labels in dataloader:
      inputs = inputs.to(device)
      outputs = model(inputs)
      _, preds = torch.max(outputs, 1)

      all_preds.extend(preds.cpu().numpy())
      all_labels.extend(labels.numpy())

  cm = confusion_matrix(all_labels, all_preds)

  plt.figure(figsize=(10, 8))
  sns.heatmap(cm, cmap='Blues')
  plt.title("Confusion Matrix (200 Classes)")
  plt.xlabel("Predicted")
  plt.ylabel("True")
  plt.show()

#그래프 그리고 혼동행렬 그리기
plot_training_history(history)
plot_confusion_matrix(trained_model, test_loader)

!pip install grad-cam

from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget
from pytorch_grad_cam.utils.image import show_cam_on_image
import numpy as np
import cv2
import matplotlib.pyplot as plt

#레이어 설정
target_layers = [model.layer4[-1]]

# Grad-CAM 객체 생성
cam = GradCAM(model=model, target_layers=target_layers)

# 시각화 함수 정의
def visualize_gradcam(model, dataloader, num_images=10):
  model.eval()

  images, labels = next(iter(dataloader))
  images = images.to(device)

  fig, axes = plt.subplots(2, 5, figsize=(20, 8))
  axes = axes.flatten()

  print(f"Test 데이터셋에서 {num_images}장을 뽑아 분석 중")

  for i in range(num_images):
    input_tensor = images[i].unsqueeze(0)

    grayscale_cam = cam(input_tensor=input_tensor, targets=None)

    grayscale_cam = grayscale_cam[0, :]

    img = images[i].cpu().permute(1, 2, 0).numpy()
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    rgb_img = img*std + mean
    rgb_img = np.clip(rgb_img, 0, 1)

    # 원본 위에 히트맵 겹치기
    visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)

    axes[i].imshow(visualization)
    axes[i].set_title(f"True: {labels[i].item()}")
    axes[i].axis('off')

  plt.tight_layout()
  plt.show()

visualize_gradcam(model, test_loader, num_images=10)

from torchvision.models.detection import fasterrcnn_resnet50_fpn
from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.image import show_cam_on_image
import cv2
import numpy as np
import matplotlib.pyplot as plt
import torch

# 1. Detection 모델 로드
print("Detection 모델(Faster R-CNN) 로드 중...")
detection_model = fasterrcnn_resnet50_fpn(pretrained=True)
detection_model = detection_model.to(device)
detection_model.eval()

COCO_BIRD_LABEL = 16

# 2. IoU 계산 및 시각화 함수 (최종 수정: Tensor/Numpy 충돌 해결)
def calculate_iou_and_visualize(classification_model, detection_model, dataloader, num_samples=5):
    classification_model.eval()

    # Grad-CAM 설정
    target_layers = [classification_model.layer4[-1]]
    cam = GradCAM(model=classification_model, target_layers=target_layers)

    images, labels = next(iter(dataloader))
    images = images.to(device)

    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5 * num_samples))
    print(f"\n총 {num_samples}개 샘플에 대해 IoU 분석을 시작합니다...\n")

    # [수정 1] GPU 연산용 Tensor (Detection 입력용)
    mean_tensor = torch.tensor([0.485, 0.456, 0.406]).to(device).view(1, 3, 1, 1)
    std_tensor = torch.tensor([0.229, 0.224, 0.225]).to(device).view(1, 3, 1, 1)

    # [수정 2] 시각화용 Numpy Array (마지막 출력용)
    mean_numpy = np.array([0.485, 0.456, 0.406])
    std_numpy = np.array([0.229, 0.224, 0.225])

    for i in range(num_samples):
        img_tensor = images[i].unsqueeze(0)

        # --- [A] Detection 결과 (Bounding Box) ---
        # 정규화 해제 (GPU Tensor 연산)
        detection_input = img_tensor * std_tensor + mean_tensor
        detection_input = torch.clamp(detection_input, 0, 1)

        with torch.no_grad():
            prediction = detection_model(detection_input)

        pred_boxes = prediction[0]['boxes']
        pred_labels = prediction[0]['labels']
        pred_scores = prediction[0]['scores']

        # '새'이면서 '확신 > 0.5'인 박스 찾기
        bird_indices = (pred_labels == COCO_BIRD_LABEL) & (pred_scores > 0.5)
        bird_boxes = pred_boxes[bird_indices]

        if len(bird_boxes) > 0:
            x1, y1, x2, y2 = bird_boxes[0].cpu().numpy().astype(int)
            target_box = [x1, y1, x2, y2]
            box_found = True
        else:
            target_box = [0, 0, 224, 224]
            box_found = False

        # Box Mask 생성
        box_mask = np.zeros((224, 224), dtype=np.uint8)
        cv2.rectangle(box_mask, (target_box[0], target_box[1]), (target_box[2], target_box[3]), 1, -1)

        # --- [B] Grad-CAM Heatmap ---
        grayscale_cam = cam(input_tensor=img_tensor, targets=None)[0, :]
        heatmap_mask = np.where(grayscale_cam > 0.2, 1, 0).astype(np.uint8)

        # --- [C] IoU 계산 ---
        intersection = (box_mask & heatmap_mask).sum()
        union = (box_mask | heatmap_mask).sum()
        iou = intersection / union if union > 0 else 0

        # --- [D] 시각화 ---
        # 원본 복구 (CPU Numpy 연산)
        img_np = images[i].cpu().permute(1, 2, 0).numpy()

        # [수정 3] 여기서 mean_numpy, std_numpy 사용! (에러 해결 포인트)
        rgb_img = np.clip(img_np * std_numpy + mean_numpy, 0, 1)

        # 1. Detection Box
        img_with_box = rgb_img.copy()
        color = (0, 1, 0) if box_found else (1, 0, 0)
        cv2.rectangle(img_with_box, (target_box[0], target_box[1]), (target_box[2], target_box[3]), color, 2)

        # 2. Heatmap
        visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)

        # 3. Overlap
        overlap_vis = np.zeros((224, 224, 3))
        overlap_vis[:, :, 1] = box_mask      # Green
        overlap_vis[:, :, 0] = heatmap_mask  # Red

        # 출력
        axes[i, 0].imshow(img_with_box)
        title = "Detection Box (Found)" if box_found else "Detection Failed"
        axes[i, 0].set_title(title)
        axes[i, 0].axis('off')

        axes[i, 1].imshow(visualization)
        axes[i, 1].set_title(f"Grad-CAM Heatmap")
        axes[i, 1].axis('off')

        axes[i, 2].imshow(overlap_vis)
        axes[i, 2].set_title(f"Overlap (IoU: {iou:.4f})")
        axes[i, 2].axis('off')

    plt.tight_layout()
    plt.show()

# 실행
calculate_iou_and_visualize(trained_model, detection_model, test_loader, num_samples=10)