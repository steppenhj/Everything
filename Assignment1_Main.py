# -*- coding: utf-8 -*-
"""Assignment1_Main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mFKOexcPeggA49e5bZYpvCeb4iW3JFbp
"""

import os

# 1. ê¼¬ì¸ í´ë”ê°€ ìˆë‹¤ë©´ ì‚­ì œ (ê¹¨ë—í•œ ìƒíƒœë¡œ ì‹œì‘)
if os.path.exists('/content/cub200'):
    !rm -rf /content/cub200
    print("ê¸°ì¡´ í´ë” ì‚­ì œ ì™„ë£Œ.")

# 2. ìºê¸€ ì¸ì¦ ì •ë³´ ë‹¤ì‹œ ì…ë ¥ (ëŸ°íƒ€ì„ ëŠê²¼ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•ˆì „í•˜ê²Œ)
# (ì•„ê¹Œ í˜œì§„ë‹˜ì´ ì£¼ì‹  í† í° ì •ë³´ ê·¸ëŒ€ë¡œì…ë‹ˆë‹¤)
os.environ['KAGGLE_USERNAME'] = "parkhaejin11111"
os.environ['KAGGLE_KEY'] = "KGAT_9a18dce92a644299734b8d3bac273a02"

# 3. ë¡œì»¬ ê²½ë¡œ(/content)ì—ì„œ ë°”ë¡œ ë‹¤ìš´ë¡œë“œ
# (êµ¬ê¸€ ë“œë¼ì´ë¸Œë¥¼ ê±°ì¹˜ì§€ ì•Šì•„ì„œ í›¨ì”¬ ë¹ ë¥´ê³  ì•ˆì •ì ì…ë‹ˆë‹¤)
os.chdir('/content')
print("ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹œì‘ (ë¡œì»¬)...")
!kaggle datasets download -d wenewone/cub2002011

# 4. ì••ì¶• í•´ì œ
print("ì••ì¶• í•´ì œ ì¤‘...")
!unzip -q cub2002011.zip -d ./cub200

# 5. [ì¤‘ìš”] ì§„ì§œ ê²½ë¡œ ì°¾ê¸°
# ì••ì¶•ì´ í’€ë¦° ë’¤ 'images' í´ë”ê°€ ì–´ë”” ìˆ¨ì–´ìˆëŠ”ì§€ íŒŒì´ì¬ì´ ì§ì ‘ ì°¾ê²Œ í•©ë‹ˆë‹¤.
print("í´ë” ìœ„ì¹˜ ì°¾ëŠ” ì¤‘...")
found_path = ""
for root, dirs, files in os.walk("/content/cub200"):
    if "images" in dirs:
        found_path = os.path.join(root, "images")
        break

if found_path:
    print(f"âœ… ì°¾ì•˜ë‹¤! ì§„ì§œ ì´ë¯¸ì§€ ê²½ë¡œ: {found_path}")
else:
    print("âŒ ì˜¤ë¥˜: images í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

import torch
import os
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, random_split

# 1. ê²½ë¡œ ì„¤ì • (ì•„ê¹Œ í™•ì¸í•œ ë¡œì»¬ ê²½ë¡œ)
data_dir = '/content/cub200/CUB_200_2011/images'
print(f"í•™ìŠµ ë°ì´í„° ê²½ë¡œ í™•ì¸: {data_dir}")

# 2. ì „ì²˜ë¦¬(Transform) ì„¤ì •
data_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# 3. ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°
# ê²½ë¡œì— í´ë”ê°€ ì‹¤ì œë¡œ ìˆëŠ”ì§€ í™•ì¸ í›„ ë¡œë“œ
if os.path.exists(data_dir):
    full_dataset = datasets.ImageFolder(root=data_dir, transform=data_transforms)
    print(f"âœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ! ì´ ì´ë¯¸ì§€: {len(full_dataset)}ì¥")

    # 4. í•™ìŠµìš©(80%) / í…ŒìŠ¤íŠ¸ìš©(20%) ë¶„ë¦¬
    train_size = int(0.8 * len(full_dataset))
    test_size = len(full_dataset) - train_size
    train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])

    # 5. ë¡œë” ìƒì„± (ë°°ì¹˜ ì‚¬ì´ì¦ˆ 32)
    # num_workers=2ëŠ” ì½”ë©ì—ì„œ ë°ì´í„° ë¡œë”© ì†ë„ë¥¼ ë†’ì—¬ì¤ë‹ˆë‹¤.
    batch_size = 32
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)

    print("ğŸ‰ ë°ì´í„° ë¡œë” ì¤€ë¹„ ì™„ë£Œ! ì´ì œ ë‹¤ìŒ ì…€(í•™ìŠµ ì½”ë“œ)ì„ ì‹¤í–‰í•˜ì„¸ìš”.")

else:
    print(f"âŒ ì˜¤ë¥˜: ê²½ë¡œì— í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤. {data_dir}ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models

# 1. GPU ì¥ì¹˜ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"í˜„ì¬ í•™ìŠµ ì¥ì¹˜: {device}")

# 2. ResNet50 ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (Pretrained)
model = models.resnet50(pretrained=True)

# ----------------------------------------------------------
# [í•µì‹¬ ë³€ê²½ì ] ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°(ì§€ì‹)ë¥¼ ì–¼ë¦½ë‹ˆë‹¤(Freeze).
# ì´ë ‡ê²Œ í•˜ë©´ ê¸°ì¡´ì— ì´ë¯¸ì§€ë„·ì—ì„œ ë°°ìš´ ë˜‘ë˜‘í•œ ì§€ì‹ì´ ìœ ì§€ë©ë‹ˆë‹¤.
for param in model.parameters():
    param.requires_grad = False
# ----------------------------------------------------------

# 3. ì¶œë ¥ì¸µ ìˆ˜ì • (ì—¬ê¸°ëŠ” ìƒˆë¡œ ë§Œë“¤ì—ˆìœ¼ë¯€ë¡œ ìë™ìœ¼ë¡œ í•™ìŠµì´ ë©ë‹ˆë‹¤)
num_features = model.fc.in_features
model.fc = nn.Linear(num_features, 200) # 200ê°œ í´ë˜ìŠ¤
model = model.to(device)

# 4. í•™ìŠµ ì„¤ì • (Optimizerê°€ 'model.fc' ì¦‰, ë§ˆì§€ë§‰ ì¸µë§Œ ê±´ë“œë¦¬ë„ë¡ ì„¤ì •)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.fc.parameters(), lr=0.001)

# 5. í•™ìŠµ ë£¨í”„ (5 Epoch)
num_epochs = 5
print(f"ğŸš€ ì„±ëŠ¥ ê°œì„ ëœ í•™ìŠµ ì‹œì‘! (ì´ {num_epochs} Epoch)")

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for i, (images, labels) in enumerate(train_loader):
        images, labels = images.to(device), labels.to(device)

        # ìˆœì „íŒŒ & ì—­ì „íŒŒ
        outputs = model(images)
        loss = criterion(outputs, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        # í†µê³„
        running_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

        if (i + 1) % 50 == 0:
            print(f"Epoch [{epoch+1}/{num_epochs}] Step [{i+1}/{len(train_loader)}] Loss: {loss.item():.4f}")

    epoch_acc = 100 * correct / total
    print(f"âœ¨ Epoch {epoch+1} ì¢…ë£Œ | í‰ê·  Loss: {running_loss/len(train_loader):.4f} | ì •í™•ë„: {epoch_acc:.2f}%")

print("ğŸ† í•™ìŠµ ì™„ë£Œ!")

# --- Fine-tuning (ì„±ëŠ¥ ë¶€ìŠ¤íŒ…) ---
print("ğŸ”¥ ì„±ëŠ¥ì„ ê·¹í•œìœ¼ë¡œ ì˜¬ë¦¬ê¸° ìœ„í•´ 'ëª¨ë“  ì¸µ'ì„ í•™ìŠµí•©ë‹ˆë‹¤ (Fine-tuning)")

# 1. ëª¨ë¸ì˜ ëª¨ë“  ì¸µì„ 'í•™ìŠµ ê°€ëŠ¥' ìƒíƒœë¡œ ë³€ê²½ (Unfreeze)
for param in model.parameters():
    param.requires_grad = True

# 2. í•™ìŠµë¥ (Learning Rate)ì„ 1/10ë¡œ ì¤„ì„
# (ì´ë¯¸ í•™ìŠµëœ ì§€ì‹ì´ ë§ê°€ì§€ì§€ ì•Šë„ë¡ ì‚´ì‚´ íŠœë‹í•˜ê¸° ìœ„í•¨)
optimizer = optim.Adam(model.parameters(), lr=0.0001)

# 3. ì¶”ê°€ í•™ìŠµ ì§„í–‰ (3 Epochë§Œ ë”!)
fine_tune_epochs = 3
print(f"ğŸš€ ì¶”ê°€ í•™ìŠµ ì‹œì‘! (ì´ {fine_tune_epochs} Epoch)")

for epoch in range(fine_tune_epochs):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for i, (images, labels) in enumerate(train_loader):
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

        if (i + 1) % 50 == 0:
             print(f"Fine-tuning Epoch [{epoch+1}/{fine_tune_epochs}] Step [{i+1}/{len(train_loader)}] Loss: {loss.item():.4f}")

    epoch_acc = 100 * correct / total
    print(f"âœ¨ ì¶”ê°€ í•™ìŠµ {epoch+1}íšŒì°¨ ì™„ë£Œ | í‰ê·  Loss: {running_loss/len(train_loader):.4f} | ì •í™•ë„: {epoch_acc:.2f}%")

print("ğŸ† ìµœì¢… í•™ìŠµ ì™„ë£Œ! ì´ì œ í‰ê°€ë¥¼ ì§„í–‰í•˜ì„¸ìš”.")

# --- ê³¼ì œ 1ë²ˆ ìµœì¢… ì œì¶œìš© ì½”ë“œ ---
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import seaborn as sns
import pandas as pd
import numpy as np

# 1. í‰ê°€ í•¨ìˆ˜ (Test Set ì •í™•ë„ ì¸¡ì •)
def final_evaluate(model, loader):
    model.eval() # í‰ê°€ ëª¨ë“œ
    all_preds = []
    all_labels = []
    correct = 0
    total = 0

    print("ğŸ“ ìµœì¢… Test ë°ì´í„°ì…‹ìœ¼ë¡œ ì±„ì  ì¤‘...")
    with torch.no_grad():
        for images, labels in loader:
            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)

            total += labels.size(0)
            correct += (predicted == labels).sum().item()

            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    acc = 100 * correct / total
    print(f"ğŸ‰ ìµœì¢… Test ì •í™•ë„: {acc:.2f}%")
    return all_labels, all_preds

# 2. í‰ê°€ ì‹¤í–‰
labels, preds = final_evaluate(model, test_loader)

# 3. í˜¼ë™ í–‰ë ¬ ì‹œê°í™” (ë³´ê³ ì„œìš©)
# 200ê°œë¥¼ ë‹¤ ê·¸ë¦¬ë©´ ë„ˆë¬´ ë³µì¡í•˜ë¯€ë¡œ, ìƒìœ„ 20ê°œ í´ë˜ìŠ¤ë§Œ ì‹œê°í™”í•©ë‹ˆë‹¤.
print("ğŸ“Š í˜¼ë™ í–‰ë ¬(Confusion Matrix) ìƒì„± ì¤‘...")
cm = confusion_matrix(labels, preds)
df_cm = pd.DataFrame(cm[:20, :20])

plt.figure(figsize=(12, 10))
sns.heatmap(df_cm, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix (First 20 Classes)")
plt.ylabel('Actual (ì •ë‹µ)')
plt.xlabel('Predicted (ì˜ˆì¸¡)')
plt.show()

# Grad-CAM ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
!pip install grad-cam
print("ì„¤ì¹˜ ì™„ë£Œ!")

from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image
from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget
import numpy as np
import cv2
import random

# 1. Grad-CAMì„ ì ìš©í•  ë ˆì´ì–´ ì„ íƒ
# ResNet50ì˜ ê²½ìš°, ê°€ì¥ ë§ˆì§€ë§‰ í•©ì„±ê³± ì¸µì¸ 'layer4ì˜ ë§ˆì§€ë§‰ ë¸”ë¡'ì„ ì£¼ë¡œ ë´…ë‹ˆë‹¤.
target_layers = [model.layer4[-1]]

# 2. Grad-CAM ê°ì²´ ìƒì„±
cam = GradCAM(model=model, target_layers=target_layers)

# 3. ì‹œê°í™” í•¨ìˆ˜ ì •ì˜
def visualize_gradcam(model, loader, num_images=10):
    model.eval()

    # Test ë°ì´í„°ì…‹ì—ì„œ ëœë¤ìœ¼ë¡œ ìƒ˜í”Œ ì¶”ì¶œ
    # datasetì€ (ì´ë¯¸ì§€í…ì„œ, ë¼ë²¨ì¸ë±ìŠ¤) íŠœí”Œë¡œ ë˜ì–´ ìˆìŒ
    indices = random.sample(range(len(loader.dataset)), num_images)

    plt.figure(figsize=(15, num_images * 3))

    for idx, sample_idx in enumerate(indices):
        img_tensor, label_idx = loader.dataset[sample_idx]

        # (1) ì…ë ¥ ì „ì²˜ë¦¬: 4ì°¨ì› ë°°ì¹˜ í˜•íƒœë¡œ ë³€í™˜ (1, 3, 224, 224)
        input_tensor = img_tensor.unsqueeze(0).to(device)

        # (2) Grad-CAM íˆíŠ¸ë§µ ìƒì„±
        # targets=Noneì´ë©´ ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ í´ë˜ìŠ¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë´„
        grayscale_cam = cam(input_tensor=input_tensor, targets=None)
        grayscale_cam = grayscale_cam[0, :] # ì²« ë²ˆì§¸ ë°°ì¹˜ì˜ ê²°ê³¼ë§Œ ê°€ì ¸ì˜´

        # (3) ì›ë³¸ ì´ë¯¸ì§€ ë³µì› (ì‹œê°í™”ë¥¼ ìœ„í•´ ì •ê·œí™” í•´ì œ)
        # í…ì„œ(GPU) -> ë„˜íŒŒì´(CPU) -> (C, H, W) -> (H, W, C)
        rgb_img = img_tensor.cpu().numpy().transpose(1, 2, 0)

        # ì •ê·œí™”(Normalize) í–ˆë˜ ê²ƒì„ ì—­ìœ¼ë¡œ ëŒë¦¼ (Mean, Std ì´ìš©)
        mean = np.array([0.485, 0.456, 0.406])
        std = np.array([0.229, 0.224, 0.225])
        rgb_img = std * rgb_img + mean
        rgb_img = np.clip(rgb_img, 0, 1) # 0~1 ì‚¬ì´ë¡œ ìë¦„

        # (4) ì´ë¯¸ì§€ ìœ„ì— íˆíŠ¸ë§µ ë§ì”Œìš°ê¸°
        visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)

        # (5) ì¶œë ¥ (ì¢Œ: ì›ë³¸, ìš°: Grad-CAM ê²°ê³¼)
        plt.subplot(num_images, 2, 2*idx + 1)
        plt.imshow(rgb_img)
        plt.title(f"Original (Class: {label_idx})")
        plt.axis('off')

        plt.subplot(num_images, 2, 2*idx + 2)
        plt.imshow(visualization)
        plt.title("Grad-CAM Heatmap")
        plt.axis('off')

    plt.tight_layout()
    plt.show()

# 4. ì‹¤í–‰ (ì´ë¯¸ì§€ 10ì¥ ì‹œê°í™”)
print("ğŸ“¸ Grad-CAM ì‹œê°í™” ê²°ê³¼ ìƒì„± ì¤‘... (ë³´ê³ ì„œì— ì´ ê·¸ë¦¼ë“¤ì„ ë„£ìœ¼ì„¸ìš”)")
visualize_gradcam(model, test_loader, num_images=10)

import torch
import numpy as np
import cv2

# 1. IoU(Intersection over Union) ê³„ì‚° í•¨ìˆ˜
# ë‘ ê°œì˜ ë„¤ëª¨ ë°•ìŠ¤ê°€ ì–¼ë§ˆë‚˜ ê²¹ì¹˜ëŠ”ì§€ 0~1 ì‚¬ì´ ìˆ«ìë¡œ ì•Œë ¤ì¤ë‹ˆë‹¤.
def calculate_iou(boxA, boxB):
    # box = [x_min, y_min, x_max, y_max]

    # ê²¹ì¹˜ëŠ” ì˜ì—­(Intersection) ì¢Œí‘œ ê³„ì‚°
    xA = max(boxA[0], boxB[0])
    yA = max(boxA[1], boxB[1])
    xB = min(boxA[2], boxB[2])
    yB = min(boxA[3], boxB[3])

    # ê²¹ì¹˜ëŠ” ë„“ì´
    interArea = max(0, xB - xA) * max(0, yB - yA)

    # ê° ë°•ìŠ¤ì˜ ë„“ì´
    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])
    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])

    # í•©ì§‘í•© ë„“ì´(Union)
    unionArea = boxAArea + boxBArea - interArea

    # IoU ê³„ì‚°
    if unionArea == 0: return 0
    iou = interArea / unionArea
    return iou

# 2. Grad-CAM íˆíŠ¸ë§µì—ì„œ ë°•ìŠ¤(Bbox) ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
# "ìƒìœ„ 20% ì´ìƒ Activation ì˜ì—­"ì„ ê¸°ì¤€ìœ¼ë¡œ ë°•ìŠ¤ë¥¼ ë§Œë“­ë‹ˆë‹¤.
def get_gradcam_bbox(heatmap, threshold=0.2):
    # íˆíŠ¸ë§µ ì •ê·œí™” (0~1)
    heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + 1e-8)

    # ì„ê³„ê°’(Threshold) ì ìš©: ìƒìœ„ 20% (0.2) ì´ìƒì¸ ë¶€ë¶„ë§Œ 1ë¡œ ë§Œë“¦ (Binary Mask)
    mask = np.where(heatmap > threshold, 1, 0).astype(np.uint8)

    # ë§ˆìŠ¤í¬ì—ì„œ ì™¸ê³½ì„ (Contour) ì°¾ê¸°
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    if not contours:
        return [0, 0, 0, 0] # ì˜ì—­ ì—†ìŒ

    # ê°€ì¥ í° ì˜ì—­ì„ ì„ íƒí•´ì„œ ë°•ìŠ¤ë¡œ ë§Œë“¦
    c = max(contours, key=cv2.contourArea)
    x, y, w, h = cv2.boundingRect(c)
    return [x, y, x+w, y+h] # [x_min, y_min, x_max, y_max]

print("ì¤€ë¹„ ì™„ë£Œ! ê³„ì‚° ë„êµ¬ë“¤ì„ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤.")

import torch
import numpy as np
import cv2
import random
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from torchvision.models.detection import fasterrcnn_resnet50_fpn

# 1. ëª¨ë¸ ì¤€ë¹„ (ì•„ê¹Œì™€ ë™ì¼)
detection_model = fasterrcnn_resnet50_fpn(pretrained=True)
detection_model.eval()
detection_model = detection_model.to(device)

# 2. ì •ê·œí™”ë¥¼ í’€ì–´ì£¼ëŠ” í•¨ìˆ˜ (NEW!)
def inverse_normalize(tensor):
    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1).to(device)
    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1).to(device)
    return tensor * std + mean

# 3. ì‹œê°í™” ë° IoU ê³„ì‚° í•¨ìˆ˜ (ìˆ˜ì •ë¨)
def visualize_iou_fixed(model, det_model, loader, num_images=5):
    # Test ì…‹ì—ì„œ ëœë¤ ì¶”ì¶œ
    indices = random.sample(range(len(loader.dataset)), num_images)

    plt.figure(figsize=(12, 6 * num_images))

    for idx, sample_idx in enumerate(indices):
        img_tensor, label_idx = loader.dataset[sample_idx]
        img_tensor = img_tensor.to(device)

        # (1) Grad-CAMìš© ì…ë ¥ (ì •ê·œí™”ëœ ìƒíƒœ ê·¸ëŒ€ë¡œ)
        input_tensor_cam = img_tensor.unsqueeze(0)

        # (2) Detectionìš© ì…ë ¥ (ì •ê·œí™”ë¥¼ í’€ì–´ì„œ ì›ë³¸ì²˜ëŸ¼ ë§Œë“¦) -> í•µì‹¬ ìˆ˜ì • ì‚¬í•­!
        input_tensor_det = inverse_normalize(img_tensor).unsqueeze(0)
        # ê°’ì´ 0~1 ë²”ìœ„ë¥¼ ë²—ì–´ë‚  ìˆ˜ ìˆìœ¼ë¯€ë¡œ í´ë¦¬í•‘
        input_tensor_det = torch.clamp(input_tensor_det, 0, 1)

        # --- A. Grad-CAM ë°•ìŠ¤ êµ¬í•˜ê¸° ---
        grayscale_cam = cam(input_tensor=input_tensor_cam, targets=None)[0, :]
        cam_bbox = get_gradcam_bbox(grayscale_cam, threshold=0.2)

        # --- B. Detection ë°•ìŠ¤ êµ¬í•˜ê¸° ---
        with torch.no_grad():
            det_outputs = det_model(input_tensor_det)

        # ê²°ê³¼ í•„í„°ë§
        pred_boxes = det_outputs[0]['boxes'].cpu().numpy()
        pred_labels = det_outputs[0]['labels'].cpu().numpy()
        pred_scores = det_outputs[0]['scores'].cpu().numpy()

        det_bbox = [0, 0, 0, 0]
        found_bird = False

        # ì ìˆ˜ ê¸°ì¤€ì„ 0.3ìœ¼ë¡œ ì¡°ê¸ˆ ë‚®ì¶°ì„œ ë” ì˜ ì°¾ê²Œ í•¨
        for box, label, score in zip(pred_boxes, pred_labels, pred_scores):
            if label == 16 and score > 0.3:
                det_bbox = box.astype(int)
                found_bird = True
                break

        # --- C. IoU ê³„ì‚° ---
        iou_score = calculate_iou(cam_bbox, det_bbox)

        # --- D. ì‹œê°í™” ---
        # ì›ë³¸ ì´ë¯¸ì§€(numpy) ë³€í™˜
        rgb_img = input_tensor_det.squeeze().cpu().numpy().transpose(1, 2, 0)

        ax = plt.subplot(num_images, 1, idx + 1)
        ax.imshow(rgb_img)

        # Grad-CAM ë°•ìŠ¤ (ì´ˆë¡)
        rect_cam = patches.Rectangle((cam_bbox[0], cam_bbox[1]),
                                     cam_bbox[2]-cam_bbox[0], cam_bbox[3]-cam_bbox[1],
                                     linewidth=3, edgecolor='lime', facecolor='none', label='Grad-CAM')
        ax.add_patch(rect_cam)

        # Detection ë°•ìŠ¤ (ë¹¨ê°•)
        if found_bird:
            rect_det = patches.Rectangle((det_bbox[0], det_bbox[1]),
                                         det_bbox[2]-det_bbox[0], det_bbox[3]-det_bbox[1],
                                         linewidth=3, edgecolor='red', facecolor='none', label='Detection')
            ax.add_patch(rect_det)
            title_text = f"IoU Score: {iou_score:.4f}"
        else:
            title_text = "Detection Failed"

        plt.title(title_text, fontsize=15, fontweight='bold', color='white', backgroundcolor='black')
        plt.legend(loc='upper right')
        plt.axis('off')

    plt.tight_layout()
    plt.show()

print("ğŸ“¸ ìˆ˜ì •ëœ IoU ë¶„ì„ ì‹œì‘! (ì´ë²ˆì—” ë¹¨ê°„ ë°•ìŠ¤ê°€ ë‚˜ì˜¬ ê²ë‹ˆë‹¤)")
visualize_iou_fixed(model, detection_model, test_loader, num_images=5)
